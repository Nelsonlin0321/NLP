{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text Classification Based on Transformer (CustomSchedule).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rk9RGI3ebfa3",
        "xVixu6X3bfcQ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Z9gfiZmbfWD"
      },
      "source": [
        "# Text Classification Based on Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CvArUrCZM5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oP58iEeZbfWM"
      },
      "source": [
        "## 1）Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcoZ7uZKZM5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size,skip_top=1,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJadXQfSZM5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivd_TnRQZM5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_word = {index:word for (word,index) in word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AAVWsPOZM5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index_to_word(indexs):\n",
        "    words = \" \".join([index_word[index] for index in indexs])\n",
        "    return words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxBFjxKtZM5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "30b0377d-94f6-4004-c00f-1a65922745f1"
      },
      "source": [
        "# Inspecting some of the text\n",
        "for i in range(3):\n",
        "    print(\"Text #\",i+1)\n",
        "    print(index_to_word(x_train[i]))\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text # 1\n",
            "the thought solid thought senator do making to is spot nomination assumed while he of jack in where picked as getting on was did hands fact characters to always life thrillers not as me can't in at are br of sure your way of little it strongly random to view of love it so principles of guy it used producer of where it of here icon film of outside to don't all unique some like of direction it if out her imagination below keep of queen he diverse to makes this stretch stefan of solid it thought begins br senator machinations budget worthwhile though ok brokedown awaiting for ever better were and diverse for budget look kicked any to of making it out and follows for effects show to show cast this family us scenes more it severe making senator to and finds tv tend to of emerged these thing wants but and an beckinsale cult as it is video do you david see scenery it in few those are of ship for with of wild to one is very work dark they don't do dvd with those them\n",
            "\n",
            "Text # 2\n",
            "the as there in at by br of sure many br of proving no only women was than doesn't as you never of hat night that with ignored they bad out superman plays of how star so stories film comes defense date of wide they don't do that had with of hollywood br of my seeing fan this of pop out body shots in having because cause it's stick passing first were enjoys for from look seven sense from me and die in character as cuban issues but is you that isn't one song just is him less are strongly not are you that different just even by this of you there is eight when it part are film's love film's 80's was big also light don't and as it in character looked cinematography so stories is far br man acting\n",
            "\n",
            "Text # 3\n",
            "the sure themes br only acting i i was favourite as on she they hat but already most was scares minor if flash was well also good 8 older was with enjoy used enjoy phone too i'm of you an job br only women than robot to was with these unexpected sure little sure guy sure on was one your life was children in particularly only yes she sort is jerry but so stories them final known to have does such most that supposed imagination very moving antonioni only yes this was seconds for imagination on this of and to plays that nights to for supposed still been last fan always your bit that strong said clean knowing br theory to car masterpiece out in also show for film's was tale have flash but look part i'm film as to penelope is script hard br only acting\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JBb8eg_AbfXL"
      },
      "source": [
        "## 2) Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJwd94FUbfXM"
      },
      "source": [
        "#### 1) Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqarrokSZM5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c9ec0f74-023d-441a-87ce-1cd74c1a6a23"
      },
      "source": [
        "tf.keras.preprocessing.sequence.pad_sequences(x_train,padding='post',maxlen=maxlen)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  194, 1153, ...,    0,    0,    0],\n",
              "       [   1,   14,   47, ...,    0,    0,    0],\n",
              "       [   1,  249, 1323, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,  118, 2362, ...,    0,    0,    0],\n",
              "       [   1,    6,  682, ...,    0,    0,    0],\n",
              "       [   1,   13, 2684, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eEr8o_28bfZy",
        "colab": {}
      },
      "source": [
        "def get_max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def padding(tensor):\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post',maxlen=maxlen)\n",
        "    \n",
        "    tensor = tf.convert_to_tensor(tensor)\n",
        "    return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty0n2zHXZM51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor_train = padding(x_train)\n",
        "\n",
        "output_tensor_train = tf.convert_to_tensor(y_train,dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zifGA6x5ZM54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "016f50a4-2c24-48a7-d3be-7099b57e0149"
      },
      "source": [
        "input_tensor_train.shape,output_tensor_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([25000, 200]), TensorShape([25000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TByqgxoOZM57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_tensor_val = padding(x_val)\n",
        "output_tensor_val = tf.convert_to_tensor(y_val,dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twRq7P7yZM6A",
        "colab_type": "code",
        "outputId": "89baaac5-29a4-4ebd-9f3b-a8021124c8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_tensor_val.shape,output_tensor_val.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([3913, 200]), TensorShape([3913]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rk9RGI3ebfa3"
      },
      "source": [
        "#### 2) DataSet Creating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m1KiH7Bmbfa4",
        "outputId": "52ece551-dfe7-4c96-b479-608ee490512b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "BUFFER_SIZE = len(x_train)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, output_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 200]), TensorShape([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QACG-ARxbfbG",
        "outputId": "9a6227b6-19ec-491d-bbc7-ed8c83ba9e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "example_input_batch"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
              "array([[    1,    14,   390, ...,     0,     0,     0],\n",
              "       [    1,    13,   119, ...,     0,     0,     0],\n",
              "       [    1,   198,    61, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    1, 13907,   174, ...,     0,     0,     0],\n",
              "       [    1,   112,    15, ...,     0,     0,     0],\n",
              "       [    1,    12,   127, ...,     0,     0,     0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7rKhV6zZM6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d90a356c-8f6a-4533-ae90-cae5dcf42bb1"
      },
      "source": [
        "example_target_batch"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "42vixHDdbfbN"
      },
      "source": [
        "## 3) Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVfcGawVZM6N",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2JBE-sQCbfbO"
      },
      "source": [
        "##### (1 )Embedding and Positional encoding  Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oN1xOM-ZM6P",
        "colab_type": "text"
      },
      "source": [
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQ_EBGdcbfbQ",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9dwyJ0aubfba",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLdsyQKvZM6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbeddingAndPosEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self,vocab_size,d_model):\n",
        "        super(EmbeddingAndPosEncoder,self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=d_model)\n",
        "        \n",
        "    def call(self,x):\n",
        "        x = self.embedding(x)\n",
        "        seq_length = x.shape[1]\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        posencode_out = positional_encoding(seq_length,self.d_model)\n",
        "        out = x+posencode_out\n",
        "        return out "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeUc9PCgZM6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCKxYUPuZM6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbedAndPosEncoderLayer = EmbeddingAndPosEncoder(vocab_size=vocab_size,d_model=embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEtcRBaqZM6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_out = EmbedAndPosEncoderLayer(example_input_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JdBi8-YZM6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f09659a4-8f64-4520-df02-34f4638f7322"
      },
      "source": [
        "embedding_out.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 200, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsMwZbFaZM6n",
        "colab_type": "text"
      },
      "source": [
        "##### (2 ) Multi-Head Attention Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Fp9Aq9ZM6n",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzxJzDdvZM6o",
        "colab_type": "text"
      },
      "source": [
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xi0_urEhbfb-",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v):\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # 缩放 matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-HQcDjdZM6s",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gA0PTy7zbfcK",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, \n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOiMHtUoZM6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MultiHeadAttentionLayer = MultiHeadAttention(512,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNL7F7VaZM60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v,k,q = embedding_out,embedding_out,embedding_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL0WudCwZM63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Attention,Weights = MultiHeadAttentionLayer(v,k,q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKwpJhesZM65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1242911-aada-49f5-cd32-f14d1ac346fc"
      },
      "source": [
        "Attention.shape,Weights.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 200, 512]), TensorShape([64, 8, 200, 200]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xVixu6X3bfcQ"
      },
      "source": [
        "#### (3) Point wise feed forward and add&Norm Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l6qRihqxbfcZ",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYondeUOZM7C",
        "colab_type": "text"
      },
      "source": [
        "#### (4) Encoder Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xudmj5yZM7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self,d_model,num_heads,dff,rate):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model,dff)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.normLayer1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.normLayer2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "    def call(self,x,training):\n",
        "        ### attention\n",
        "        attn_output,attentionWeight = self.mha(x,x,x)\n",
        "        ### add&Norm\n",
        "        attn_output = self.dropout1(attn_output,training=training)\n",
        "        out1 = self.normLayer1(attn_output+x)\n",
        "        \n",
        "        out2 = self.ffn(out1)\n",
        "        out2 = self.dropout2(out2,training = training)\n",
        "        out2 = self.normLayer2(out2+out1)\n",
        "        \n",
        "        return out2,attentionWeight\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OTgcyrbZM7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoderLayer = Encoder(512,8,1024,0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZurEDZNJZM7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampleEncderOutput,sampleAttentionWeight = encoderLayer(tf.random.uniform([64,200,512]),True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bh30d2zZbfc3"
      },
      "source": [
        "#### (6) Transfomer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg3qsf1Zbfc4",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,vocab_size,d_model,num_layers,num_heads,dff,rate,final_hidden_units,num_classes):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.embedAndPosEncoderLayer = EmbeddingAndPosEncoder(vocab_size,d_model)\n",
        "        self.enc_layers = [Encoder(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.globalPooling= tf.keras.layers.GlobalAveragePooling1D()\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dense = tf.keras.layers.Dense(final_hidden_units,activation=\"relu\")\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.final_layer = tf.keras.layers.Dense(num_classes,activation=\"softmax\")\n",
        "        \n",
        "\n",
        "    def call(self,inp,training):\n",
        "        attention_weights = []\n",
        "        \n",
        "        x = self.embedAndPosEncoderLayer(inp)\n",
        "        \n",
        "        for encoderLayer in self.enc_layers:\n",
        "            x,attentionweight = encoderLayer(x,training)\n",
        "            attention_weights.append(attentionweight)\n",
        "        \n",
        "        x = self.globalPooling(x)\n",
        "        x = self.dropout1(x,training)\n",
        "        x = self.dense(x)\n",
        "        x = self.dropout2(x,training)\n",
        "\n",
        "        final_output = self.final_layer(x)\n",
        "\n",
        "        return final_output,attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJsrHBXEZM7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_transformer = Transformer(vocab_size=2000,d_model=512,num_layers=3,num_heads=8,dff=1024,rate=0.1,final_hidden_units=64,num_classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymjiTk6rZM7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_output,sample_attentionWeight = sample_transformer(tf.random.uniform((64, 62)),True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJU1eLHZM7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40105001-31c1-4f85-b3a3-6a18b51a2da6"
      },
      "source": [
        "sample_output.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JTfn90EhbfdB"
      },
      "source": [
        "#### (7) hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wq9maWKGbfdI",
        "colab": {}
      },
      "source": [
        "num_layers = 2\n",
        "d_model = 128\n",
        "final_hidden_units = 64\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "vocab_size = vocab_size\n",
        "dropout_rate = 0.1\n",
        "num_classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdkgYboQZM7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_classifer = Transformer(vocab_size=vocab_size,d_model=d_model,num_layers=num_layers,num_heads=num_heads,\n",
        "                             dff=dff,rate=dropout_rate,final_hidden_units=final_hidden_units,num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCcPNY9XZM7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.layers.Input(shape=(maxlen,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAD29t7iZM7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs,attention_weight = text_classifer(inputs,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYBXYxLzZM70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Model(inputs = inputs,outputs = outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1yhOJKZM73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "# history = model.fit(\n",
        "#     input_tensor_train.numpy(), output_tensor_train.numpy(), batch_size=32, epochs=10, validation_data=(input_tensor_val.numpy() , output_tensor_val.numpy())\n",
        "# )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_pd6l6ZZM7_",
        "colab_type": "text"
      },
      "source": [
        "#### (8) Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIyy2j39ZM8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -0.8)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c297xeBYZM8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "38014c93-085e-416f-b9e7-9d4a8638a037"
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(400, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvFADBMLZM8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgniDxuXZM8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e38ce39-961a-4539-b679-d8fec34ea991"
      },
      "source": [
        "learning_rate"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.CustomSchedule at 0x7ff2be18f208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPB0ExLCZM8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_B_AMDOZM8S",
        "colab_type": "text"
      },
      "source": [
        "#### (9) Loss and metrics¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IPqtuOIZM8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False, reduction='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSs9kq59ZM8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1ef54cd-0486-4f29-8b51-8eaac7540b76"
      },
      "source": [
        "example_target_batch.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eX4dAe6ZM8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c73930d-23f4-4f4a-8b3e-cc355763f493"
      },
      "source": [
        "sample_output.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P8jrgnhZM8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9beb2d6a-0a7b-403b-998d-109eadb3928e"
      },
      "source": [
        "loss_function(example_target_batch,sample_output)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9165926>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDhaMAnqZM8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im2-rmYkZM8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='val_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99xgWk51ZM8v",
        "colab_type": "text"
      },
      "source": [
        "#### (10) Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDLJTWjRZM8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4bd0df1-e07c-4724-da7d-db62119052ed"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(text_classifer=text_classifer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# 如果检查点存在，则恢复最新的检查点。\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR9n5NOZZM8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAV9KBwIZM83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = True "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5hOrls1ZM86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6993a431-50ea-4251-cc44-f224f1d50e80"
      },
      "source": [
        "example_input_batch"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
              "array([[    1,    14,   390, ...,     0,     0,     0],\n",
              "       [    1,    13,   119, ...,     0,     0,     0],\n",
              "       [    1,   198,    61, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    1, 13907,   174, ...,     0,     0,     0],\n",
              "       [    1,   112,    15, ...,     0,     0,     0],\n",
              "       [    1,    12,   127, ...,     0,     0,     0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB5OI3CbZM88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX5MWxjRZM8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "a90dab43-b4fb-43bb-8bc0-c90497190fd1"
      },
      "source": [
        "input_tensor_val[:64,]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
              "array([[   1,    4, 2026, ...,    0,    0,    0],\n",
              "       [   1,   13, 2488, ...,    0,    0,    0],\n",
              "       [   1,    4,   65, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,   51,   70, ...,    0,    0,    0],\n",
              "       [   1,   39,    4, ...,    0,    0,    0],\n",
              "       [   1,  112,    6, ...,    0,    0,    0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXi7wSnZZM9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val, _ = text_classifer(input_tensor_val[:64,],testing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9-FwWTaZM9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_step_signature = [\n",
        "#     tf.TensorSpec(shape=(BATCH_SIZE, None), dtype=tf.int32),\n",
        "#     tf.TensorSpec(shape=(BATCH_SIZE, None), dtype=tf.int32),\n",
        "#     tf.TensorSpec(shape=(BATCH_SIZE, None), dtype=tf.int32),\n",
        "#     tf.TensorSpec(shape=(BATCH_SIZE, None), dtype=tf.int32),\n",
        "# ]\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = text_classifer(inp,True)\n",
        "        loss = loss_function(tar, predictions)\n",
        "        \n",
        "    gradients = tape.gradient(loss, text_classifer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, text_classifer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrNaJqYDZM9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_step(inp_val,tar_val):\n",
        "    predictions_val, _ = text_classifer(inp_val,False)\n",
        "    loss_val = loss_function(tar_val, predictions_val)\n",
        "    \n",
        "    val_loss(loss_val)\n",
        "    val_accuracy(tar_val,predictions_val)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWuLxBRudC_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "b708b29a-71e8-4d18-85fb-c2c918811fc6"
      },
      "source": [
        "input_tensor_val"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3913, 200), dtype=int32, numpy=\n",
              "array([[   1,    4, 2026, ...,    0,    0,    0],\n",
              "       [   1,   13, 2488, ...,    0,    0,    0],\n",
              "       [   1,    4,   65, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,   13, 1408, ...,    0,    0,    0],\n",
              "       [   1,   11,  119, ...,    0,    0,    0],\n",
              "       [   1,    6,   52, ...,    0,    0,    0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFkiJ4rSdDpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6fbaa178-0499-43db-802a-7d11b154c240"
      },
      "source": [
        "output_tensor_val"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3913,), dtype=float32, numpy=array([0., 0., 1., ..., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1MTFAigZM9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, output_tensor_val)).shuffle(len(input_tensor_val))\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwzjJ54OcA6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7d3af8b5-7cb9-485b-be8c-f7939af7ba3f"
      },
      "source": [
        "next(iter(val_dataset))[1]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8DFYM6nZM9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca2bece4-9c0f-4ff7-d4c5-51eb2e4356c8"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    val_loss.reset_states()\n",
        "    val_accuracy.reset_states()\n",
        "\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        \n",
        "        train_step(inp, tar)\n",
        "        \n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Traing Loss {:.4f} Traing Accuracy {:.4f}'.format(\n",
        "                epoch + 1, batch, train_loss.result(), train_accuracy.result(), ))\n",
        "\n",
        "\n",
        "    for (val_inp,val_tar) in val_dataset:\n",
        "        val_step(val_inp,val_tar)\n",
        "    \n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n",
        "\n",
        "    print ('Epoch {} Training Loss {:.4f} Training Accuracy {:.4f} Val Loss {:.4f} Val Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result(),\n",
        "                                                val_loss.result(),\n",
        "                                                val_accuracy.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Traing Loss 0.2706 Traing Accuracy 0.8594\n",
            "Epoch 1 Batch 50 Traing Loss 0.2091 Traing Accuracy 0.9222\n",
            "Epoch 1 Batch 100 Traing Loss 0.2181 Traing Accuracy 0.9172\n",
            "Epoch 1 Batch 150 Traing Loss 0.2205 Traing Accuracy 0.9153\n",
            "Epoch 1 Batch 200 Traing Loss 0.2256 Traing Accuracy 0.9124\n",
            "Epoch 1 Batch 250 Traing Loss 0.2300 Traing Accuracy 0.9116\n",
            "Epoch 1 Batch 300 Traing Loss 0.2310 Traing Accuracy 0.9110\n",
            "Epoch 1 Batch 350 Traing Loss 0.2328 Traing Accuracy 0.9095\n",
            "Epoch 1 Training Loss 0.2341 Training Accuracy 0.9082 Val Loss 0.3929 Val Accuracy 0.8404\n",
            "Time taken for 1 epoch: 22.49802851676941 secs\n",
            "\n",
            "Epoch 2 Batch 0 Traing Loss 0.1722 Traing Accuracy 0.9062\n",
            "Epoch 2 Batch 50 Traing Loss 0.2119 Traing Accuracy 0.9213\n",
            "Epoch 2 Batch 100 Traing Loss 0.2218 Traing Accuracy 0.9148\n",
            "Epoch 2 Batch 150 Traing Loss 0.2200 Traing Accuracy 0.9136\n",
            "Epoch 2 Batch 200 Traing Loss 0.2231 Traing Accuracy 0.9132\n",
            "Epoch 2 Batch 250 Traing Loss 0.2255 Traing Accuracy 0.9125\n",
            "Epoch 2 Batch 300 Traing Loss 0.2239 Traing Accuracy 0.9142\n",
            "Epoch 2 Batch 350 Traing Loss 0.2251 Traing Accuracy 0.9132\n",
            "Epoch 2 Training Loss 0.2249 Training Accuracy 0.9125 Val Loss 0.3819 Val Accuracy 0.8430\n",
            "Time taken for 1 epoch: 20.92406964302063 secs\n",
            "\n",
            "Epoch 3 Batch 0 Traing Loss 0.2024 Traing Accuracy 0.9531\n",
            "Epoch 3 Batch 50 Traing Loss 0.2025 Traing Accuracy 0.9246\n",
            "Epoch 3 Batch 100 Traing Loss 0.2002 Traing Accuracy 0.9256\n",
            "Epoch 3 Batch 150 Traing Loss 0.2016 Traing Accuracy 0.9250\n",
            "Epoch 3 Batch 200 Traing Loss 0.2067 Traing Accuracy 0.9231\n",
            "Epoch 3 Batch 250 Traing Loss 0.2088 Traing Accuracy 0.9216\n",
            "Epoch 3 Batch 300 Traing Loss 0.2116 Traing Accuracy 0.9199\n",
            "Epoch 3 Batch 350 Traing Loss 0.2137 Traing Accuracy 0.9187\n",
            "Epoch 3 Training Loss 0.2138 Training Accuracy 0.9184 Val Loss 0.4206 Val Accuracy 0.8422\n",
            "Time taken for 1 epoch: 20.87139081954956 secs\n",
            "\n",
            "Epoch 4 Batch 0 Traing Loss 0.1405 Traing Accuracy 0.9531\n",
            "Epoch 4 Batch 50 Traing Loss 0.1908 Traing Accuracy 0.9283\n",
            "Epoch 4 Batch 100 Traing Loss 0.1915 Traing Accuracy 0.9290\n",
            "Epoch 4 Batch 150 Traing Loss 0.1869 Traing Accuracy 0.9292\n",
            "Epoch 4 Batch 200 Traing Loss 0.1881 Traing Accuracy 0.9291\n",
            "Epoch 4 Batch 250 Traing Loss 0.1922 Traing Accuracy 0.9277\n",
            "Epoch 4 Batch 300 Traing Loss 0.1961 Traing Accuracy 0.9260\n",
            "Epoch 4 Batch 350 Traing Loss 0.1979 Traing Accuracy 0.9253\n",
            "Epoch 4 Training Loss 0.2009 Training Accuracy 0.9238 Val Loss 0.4075 Val Accuracy 0.8432\n",
            "Time taken for 1 epoch: 20.847769021987915 secs\n",
            "\n",
            "Epoch 5 Batch 0 Traing Loss 0.1211 Traing Accuracy 0.9375\n",
            "Epoch 5 Batch 50 Traing Loss 0.1793 Traing Accuracy 0.9326\n",
            "Epoch 5 Batch 100 Traing Loss 0.1857 Traing Accuracy 0.9318\n",
            "Epoch 5 Batch 150 Traing Loss 0.1908 Traing Accuracy 0.9288\n",
            "Epoch 5 Batch 200 Traing Loss 0.1885 Traing Accuracy 0.9307\n",
            "Epoch 5 Batch 250 Traing Loss 0.1894 Traing Accuracy 0.9302\n",
            "Epoch 5 Batch 300 Traing Loss 0.1911 Traing Accuracy 0.9292\n",
            "Epoch 5 Batch 350 Traing Loss 0.1937 Traing Accuracy 0.9280\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-2\n",
            "Epoch 5 Training Loss 0.1933 Training Accuracy 0.9285 Val Loss 0.4754 Val Accuracy 0.8363\n",
            "Time taken for 1 epoch: 20.94085168838501 secs\n",
            "\n",
            "Epoch 6 Batch 0 Traing Loss 0.4113 Traing Accuracy 0.8438\n",
            "Epoch 6 Batch 50 Traing Loss 0.1691 Traing Accuracy 0.9375\n",
            "Epoch 6 Batch 100 Traing Loss 0.1774 Traing Accuracy 0.9355\n",
            "Epoch 6 Batch 150 Traing Loss 0.1753 Traing Accuracy 0.9359\n",
            "Epoch 6 Batch 200 Traing Loss 0.1802 Traing Accuracy 0.9341\n",
            "Epoch 6 Batch 250 Traing Loss 0.1830 Traing Accuracy 0.9334\n",
            "Epoch 6 Batch 300 Traing Loss 0.1832 Traing Accuracy 0.9322\n",
            "Epoch 6 Batch 350 Traing Loss 0.1826 Traing Accuracy 0.9320\n",
            "Epoch 6 Training Loss 0.1821 Training Accuracy 0.9320 Val Loss 0.4627 Val Accuracy 0.8399\n",
            "Time taken for 1 epoch: 21.04852533340454 secs\n",
            "\n",
            "Epoch 7 Batch 0 Traing Loss 0.3081 Traing Accuracy 0.8750\n",
            "Epoch 7 Batch 50 Traing Loss 0.1714 Traing Accuracy 0.9378\n",
            "Epoch 7 Batch 100 Traing Loss 0.1708 Traing Accuracy 0.9373\n",
            "Epoch 7 Batch 150 Traing Loss 0.1700 Traing Accuracy 0.9378\n",
            "Epoch 7 Batch 200 Traing Loss 0.1702 Traing Accuracy 0.9376\n",
            "Epoch 7 Batch 250 Traing Loss 0.1687 Traing Accuracy 0.9382\n",
            "Epoch 7 Batch 300 Traing Loss 0.1698 Traing Accuracy 0.9373\n",
            "Epoch 7 Batch 350 Traing Loss 0.1703 Traing Accuracy 0.9373\n",
            "Epoch 7 Training Loss 0.1712 Training Accuracy 0.9370 Val Loss 0.4566 Val Accuracy 0.8376\n",
            "Time taken for 1 epoch: 20.840665102005005 secs\n",
            "\n",
            "Epoch 8 Batch 0 Traing Loss 0.1085 Traing Accuracy 0.9844\n",
            "Epoch 8 Batch 50 Traing Loss 0.1615 Traing Accuracy 0.9409\n",
            "Epoch 8 Batch 100 Traing Loss 0.1608 Traing Accuracy 0.9423\n",
            "Epoch 8 Batch 150 Traing Loss 0.1591 Traing Accuracy 0.9440\n",
            "Epoch 8 Batch 200 Traing Loss 0.1578 Traing Accuracy 0.9440\n",
            "Epoch 8 Batch 250 Traing Loss 0.1578 Traing Accuracy 0.9431\n",
            "Epoch 8 Batch 300 Traing Loss 0.1590 Traing Accuracy 0.9420\n",
            "Epoch 8 Batch 350 Traing Loss 0.1619 Traing Accuracy 0.9415\n",
            "Epoch 8 Training Loss 0.1632 Training Accuracy 0.9410 Val Loss 0.4830 Val Accuracy 0.8368\n",
            "Time taken for 1 epoch: 20.83731698989868 secs\n",
            "\n",
            "Epoch 9 Batch 0 Traing Loss 0.1465 Traing Accuracy 0.9375\n",
            "Epoch 9 Batch 50 Traing Loss 0.1413 Traing Accuracy 0.9513\n",
            "Epoch 9 Batch 100 Traing Loss 0.1430 Traing Accuracy 0.9485\n",
            "Epoch 9 Batch 150 Traing Loss 0.1425 Traing Accuracy 0.9483\n",
            "Epoch 9 Batch 200 Traing Loss 0.1451 Traing Accuracy 0.9481\n",
            "Epoch 9 Batch 250 Traing Loss 0.1470 Traing Accuracy 0.9473\n",
            "Epoch 9 Batch 300 Traing Loss 0.1488 Traing Accuracy 0.9462\n",
            "Epoch 9 Batch 350 Traing Loss 0.1506 Traing Accuracy 0.9456\n",
            "Epoch 9 Training Loss 0.1538 Training Accuracy 0.9447 Val Loss 0.4818 Val Accuracy 0.8397\n",
            "Time taken for 1 epoch: 20.826541662216187 secs\n",
            "\n",
            "Epoch 10 Batch 0 Traing Loss 0.1251 Traing Accuracy 0.9531\n",
            "Epoch 10 Batch 50 Traing Loss 0.1434 Traing Accuracy 0.9528\n",
            "Epoch 10 Batch 100 Traing Loss 0.1420 Traing Accuracy 0.9502\n",
            "Epoch 10 Batch 150 Traing Loss 0.1414 Traing Accuracy 0.9503\n",
            "Epoch 10 Batch 200 Traing Loss 0.1417 Traing Accuracy 0.9499\n",
            "Epoch 10 Batch 250 Traing Loss 0.1420 Traing Accuracy 0.9500\n",
            "Epoch 10 Batch 300 Traing Loss 0.1418 Traing Accuracy 0.9497\n",
            "Epoch 10 Batch 350 Traing Loss 0.1437 Traing Accuracy 0.9487\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-3\n",
            "Epoch 10 Training Loss 0.1439 Training Accuracy 0.9486 Val Loss 0.4938 Val Accuracy 0.8397\n",
            "Time taken for 1 epoch: 20.90208888053894 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-uwbkQTaZta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}